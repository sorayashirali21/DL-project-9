
from nltk.tokenize import word_tokenize
sent = '''I am reading a book.
          It is Python Machine Learning By Example,
          3nd edition.'''

print(word_tokenize(sent))

sent2 = 'I have been to U.K. and U.S.A.'
print(word_tokenize(sent2))

